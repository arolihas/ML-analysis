{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "\n",
    "*Remove misclassified data and extraneous columns*\n",
    "\n",
    "*Split data into training and testing sets*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix,f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Plotting Learning Curve Function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and training learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 3-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - An object to be used as a cross-validation generator.\n",
    "          - An iterable yielding train/test splits.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : integer, optional\n",
    "        Number of jobs to run in parallel (default 1).\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Confusion Matrix Plotting*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"default of credit card clients.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['ID'],axis=1)\n",
    "data = data[data.MARRIAGE != 3]\n",
    "data = data[data.MARRIAGE != 0]\n",
    "data = data[data.EDUCATION < 3]\n",
    "data = data[data.EDUCATION != 0]\n",
    "data.loc[:,['SEX','EDUCATION','MARRIAGE']] -= 1\n",
    "data.loc[:,'MARRIAGE'] ^= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['default payment next month']\n",
    "X = data.drop(['default payment next month'], axis=1)\n",
    "y.value_counts().plot(kind='bar',title ='CC Unbalanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c0, c1 = y.value_counts()\n",
    "data0 = data[y==0]\n",
    "data1 = data[y==1]\n",
    "\n",
    "data0under = data0.sample(c1)\n",
    "\n",
    "dataUnder = pd.concat([data0under, data1],axis=0)\n",
    "dataUnder.describe()\n",
    "\n",
    "y = dataUnder['default payment next month']\n",
    "X = dataUnder.drop(['default payment next month'], axis=1)\n",
    "y.value_counts().plot(kind='bar',title='CC Balanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sizes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small = dataUnder.sample(frac=.01)\n",
    "medium = dataUnder.sample(frac=.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scaled data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler = StandardScaler()  \n",
    "# Don't cheat - fit only on training data\n",
    "scaler.fit(train_X)  \n",
    "train_Xs = scaler.transform(train_X)  \n",
    "# apply same transformation to test data\n",
    "val_Xs = scaler.transform(val_X)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tModel = DecisionTreeClassifier(criterion='entropy')\n",
    "title = \"Decision Tree (No pruning)\"\n",
    "plot_learning_curve(tModel,title, train_X, train_y, ylim=(0.5, 1.01), cv=5, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "crossVal = cross_val_score(tModel, train_X, train_y, cv=5)\n",
    "print(\"Unpruned:\",np.mean(crossVal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-puning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,10):\n",
    "    tModel = DecisionTreeClassifier(criterion='entropy',max_depth=i)\n",
    "    title = \"Decision Tree of Max Depth: \" + str(i)\n",
    "    plot_learning_curve(tModel,title, train_X, train_y, ylim=(0.5, 1.01), cv=5, n_jobs=4)\n",
    "    crossVal = cross_val_score(tModel, train_X, train_y, cv=5)\n",
    "    print(\"Pruned:\",i,np.mean(crossVal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tModel = DecisionTreeClassifier(criterion='entropy',max_depth=3)\n",
    "pred_y = tModel.fit(train_X, train_y).predict(val_X)\n",
    "cnf_matrix = confusion_matrix(val_y, pred_y)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['default','not default'],\n",
    "                      normalize=True, title='Decision Tree Confusion Matrix')\n",
    "\n",
    "print(\"Score\", tModel.score(val_X, val_y))\n",
    "print(\"F1 Score\",f1_score(pred_y, val_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Size of Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ty = tiny['default payment next month']\n",
    "tX = tiny.drop(['default payment next month'], axis=1)\n",
    "ttrain_X, tval_X, ttrain_y, tval_y = train_test_split(tX, ty, random_state = 0)\n",
    "sy = small['default payment next month']\n",
    "sX = small.drop(['default payment next month'], axis=1)\n",
    "strain_X, sval_X, strain_y, sval_y = train_test_split(sX, sy, random_state = 0)\n",
    "my = medium['default payment next month']\n",
    "mX = medium.drop(['default payment next month'], axis=1)\n",
    "mtrain_X, mval_X, mtrain_y, mval_y = train_test_split(mX, my, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Decision Tree (n=106)\"\n",
    "plot_learning_curve(tModel,title, strain_X, strain_y, ylim=(0.4, 1.01), cv=5, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Decision Tree (n=1062)\"\n",
    "plot_learning_curve(tModel,title, mtrain_X, mtrain_y, ylim=(0.5, 1.01), cv=5, n_jobs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "nn = MLPClassifier(solver='adam',hidden_layer_sizes=(12,),\n",
    "                   early_stopping=True,random_state=1)\n",
    "print(nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = {'solver':['adam','sgd','lbfgs'],'alpha': 10**-np.arange(1,7,dtype=float),\n",
    "          'learning_rate':['constant','adaptive'],\n",
    "          'hidden_layer_sizes':range(12,63,10)}\n",
    "gs = GridSearchCV(estimator=nn, param_grid=params,cv=5)\n",
    "gs.fit(train_Xs, train_y)\n",
    "print(gs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Default MLPClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Default Neural Network\"\n",
    "plot_learning_curve(nn,title, train_Xs, train_y, ylim=(0.5, 1.01), cv=5, n_jobs=4)\n",
    "crossVal = cross_val_score(nn, train_Xs, train_y, cv=5)\n",
    "print(\"Untuned:\",np.mean(crossVal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tuned Neural Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Neural Network After Tuning Hyperparameters\"\n",
    "gnn = gs.best_estimator_\n",
    "print(gnn)\n",
    "plot_learning_curve(gnn, title, train_Xs, train_y, ylim=(0.5, 1.01), cv=5, n_jobs=4)\n",
    "crossVal = cross_val_score(gnn, train_Xs, train_y, cv=5)\n",
    "print(\"Tuned:\",np.mean(crossVal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gnn.score(val_Xs, val_y))\n",
    "pred_y = gnn.fit(train_Xs, train_y).predict(val_Xs)\n",
    "cnf_matrix = confusion_matrix(val_y, pred_y)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['default','not default'],\n",
    "                      normalize=True, title='Neural Network Confusion Matrix')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Size of Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sy = small['default payment next month']\n",
    "sX = small.drop(['default payment next month'], axis=1)\n",
    "strain_X, sval_X, strain_y, sval_y = train_test_split(sX, sy, random_state = 0)\n",
    "scaler.fit(strain_X)  \n",
    "strain_Xs = scaler.transform(strain_X)  \n",
    "# apply same transformation to test data\n",
    "sval_Xs = scaler.transform(sval_X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Neural Network (n=106)\"\n",
    "nn = MLPClassifier(solver='lbfgs',random_state=1)\n",
    "plot_learning_curve(nn,title, strain_Xs, strain_y, ylim=(0.5, 1.01), cv=5, n_jobs=4)\n",
    "crossVal = cross_val_score(nn, strain_Xs, strain_y, cv=5)\n",
    "print(\"Untuned:\",np.mean(crossVal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my = medium['default payment next month']\n",
    "mX = medium.drop(['default payment next month'], axis=1)\n",
    "mtrain_X, mval_X, mtrain_y, mval_y = train_test_split(mX, my, random_state = 0)\n",
    "scaler.fit(mtrain_X)  \n",
    "mtrain_Xs = scaler.transform(mtrain_X)  \n",
    "# apply same transformation to test data\n",
    "mval_Xs = scaler.transform(mval_X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Neural Network (n=1062)\"\n",
    "nn = MLPClassifier(solver='lbfgs',random_state=1)\n",
    "plot_learning_curve(nn,title, mtrain_Xs, mtrain_y, ylim=(0.5, 1.01), cv=5, n_jobs=4)\n",
    "crossVal = cross_val_score(nn, mtrain_Xs, mtrain_y, cv=5)\n",
    "print(\"Untuned:\",np.mean(crossVal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "bdt = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(criterion='entropy',max_depth=1))\n",
    "bdt.fit(train_X, train_y)\n",
    "title = \"Default AdaBoost\"\n",
    "plot_learning_curve(bdt,title, train_X, train_y, ylim=(0.5, 1.01), cv=5, n_jobs=4)\n",
    "crossVal = cross_val_score(bdt, train_X, train_y, cv=5)\n",
    "print(\"Untuned\",np.mean(crossVal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "params = {'learning_rate': np.logspace(-10,1,11),'n_estimators':range(10,400,50)}\n",
    "rs = GridSearchCV(estimator=bdt, param_grid=params,cv=3,verbose=5)\n",
    "rs.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"AdaBoost After Tuning Hyperparameters\"\n",
    "bdt = rs.best_estimator_\n",
    "plot_learning_curve(bdt, title, train_X, train_y, ylim=(0.5, 1.01), cv=5, n_jobs=4)\n",
    "crossVal = cross_val_score(bdt, train_X, train_y, cv=5)\n",
    "print(\"Tuned:\",np.mean(crossVal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bdt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bdt.score(val_X, val_y))\n",
    "pred_y = bdt.fit(train_X, train_y).predict(val_X)\n",
    "cnf_matrix = confusion_matrix(val_y, pred_y)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['default','not default'],\n",
    "                      normalize=True, title='AdaBoost Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Size of Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"AdaBoost (n=106)\"\n",
    "plot_learning_curve(bdt,title, strain_X, strain_y, ylim=(0.5, 1.01), cv=5, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"AdaBoost (n=1062)\"\n",
    "plot_learning_curve(bdt,title, mtrain_X, mtrain_y, ylim=(0.5, 1.01), cv=5, n_jobs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "svmClf = svm.SVC()\n",
    "svmClf.fit(train_Xs, train_y)\n",
    "title = \"Default SVM\"\n",
    "plot_learning_curve(svmClf,title, train_Xs, train_y, ylim=(0.5, 1.01), cv=5, n_jobs=4)\n",
    "crossVal = cross_val_score(svmClf, train_Xs, train_y, cv=5)\n",
    "print(\"Untuned\",np.mean(crossVal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {'gamma': np.logspace(-3, -2, 3),\n",
    "            'C': np.logspace(1,2,5)}\n",
    "gs = GridSearchCV(estimator=svmClf, param_grid=params,cv=3,scoring='f1')\n",
    "gs.fit(train_Xs, train_y)\n",
    "print(gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"SVM After Tuning\"\n",
    "svmClf = gs.best_estimator_\n",
    "plot_learning_curve(svmClf, title, train_Xs, train_y, ylim=(0.5, 1.01), cv=5, n_jobs=4)\n",
    "crossVal = cross_val_score(svmClf, train_Xs, train_y, cv=5)\n",
    "print(\"Tuned:\",np.mean(crossVal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(svmClf.score(val_Xs, val_y))\n",
    "pred_y = svmClf.fit(train_Xs, train_y).predict(val_Xs)\n",
    "cnf_matrix = confusion_matrix(val_y, pred_y)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['default','not default'],\n",
    "                      normalize=True, title='SVM Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Size of Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"SVM (n=106)\"\n",
    "plot_learning_curve(svmClf,title, strain_Xs, strain_y, ylim=(0.5, 1.01), cv=5, n_jobs=4)\n",
    "crossVal = cross_val_score(svmClf, strain_Xs, strain_y, cv=5)\n",
    "print(\"Untuned:\",np.mean(crossVal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"SVM (n=1062)\"\n",
    "nn = MLPClassifier(solver='lbfgs',random_state=1)\n",
    "plot_learning_curve(svmClf,title, mtrain_Xs, mtrain_y, ylim=(0.5, 1.01), cv=5, n_jobs=4)\n",
    "crossVal = cross_val_score(svmClf, mtrain_Xs, mtrain_y, cv=5)\n",
    "print(\"Untuned:\",np.mean(crossVal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "knn = neighbors.KNeighborsClassifier()\n",
    "knn.fit(train_Xs, train_y)\n",
    "title = \"Default k-NN\"\n",
    "plot_learning_curve(knn,title, train_Xs, train_y, ylim=(0.5, 1.01), cv=5, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossVal = cross_val_score(knn, train_Xs, train_y, cv=5)\n",
    "print(\"Untuned\",np.mean(crossVal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {'n_neighbors': range(1,51), 'weights':['uniform','distance'], 'p': range(1,3)}\n",
    "gs = GridSearchCV(estimator=knn, param_grid=params,cv=3,scoring='f1')\n",
    "gs.fit(train_Xs, train_y)\n",
    "print(gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"k-NN After Tuning\"\n",
    "knn = gs.best_estimator_\n",
    "plot_learning_curve(knn, title, train_Xs, train_y, ylim=(0.5, 1.01), cv=5, n_jobs=4)\n",
    "crossVal = cross_val_score(knn, train_Xs, train_y, cv=5)\n",
    "print(\"Tuned:\",np.mean(crossVal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(knn)\n",
    "strain_y.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(knn.score(val_Xs, val_y))\n",
    "pred_y = knn.fit(train_Xs, train_y).predict(val_Xs)\n",
    "cnf_matrix = confusion_matrix(val_y, pred_y)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['default','not default'],\n",
    "                      normalize=True, title='k-NN Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Size of Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"kNN (n=1062)\"\n",
    "plot_learning_curve(knn,title, mtrain_Xs, mtrain_y, ylim=(0.5, 1.01), cv=5, n_jobs=4)\n",
    "crossVal = cross_val_score(knn, mtrain_Xs, mtrain_y, cv=5)\n",
    "print(np.mean(crossVal))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
