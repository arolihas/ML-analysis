{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "training = pd.read_csv(\"fer2013train.csv\")\n",
    "test = pd.read_csv(\"fer2013test.csv\")\n",
    "full = pd.concat([training,test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and training learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 3-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - An object to be used as a cross-validation generator.\n",
    "          - An iterable yielding train/test splits.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : integer, optional\n",
    "        Number of jobs to run in parallel (default 1).\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = full[full.emotion != 1]\n",
    "zeros = full[full.emotion == 0]\n",
    "oneHigh = full[full.emotion != 0]\n",
    "oneHigh.loc[:,'emotion'] -= 1\n",
    "full = pd.concat([zeros, oneHigh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = full.sample(frac=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = full.emotion\n",
    "y.value_counts().plot(kind='bar',title ='FER Unbalanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c0, c1,c2,c3,c4,c5 = y.value_counts()\n",
    "data0 = full[y==0].sample(c5)\n",
    "data1 = full[y==1].sample(c5)\n",
    "data2 = full[y==2].sample(c5)\n",
    "data3 = full[y==3].sample(c5)\n",
    "data4 = full[y==4].sample(c5)\n",
    "data5 = full[y==5].sample(c5)\n",
    "\n",
    "fullUnder = pd.concat([data0, data1,data2,data3,data4,data5],axis=0)\n",
    "fullUnder.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = fullUnder.emotion\n",
    "x = fullUnder.pixels\n",
    "x = pd.DataFrame(x.str.split().values.tolist())\n",
    "y.value_counts().plot(kind='bar',title='FER Balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medium = fullUnder.sample(frac=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my = medium.emotion\n",
    "mx = pd.DataFrame(medium.pixels.str.split().values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, val_x, train_y, val_y = train_test_split(x, y, random_state = 0)\n",
    "train_xm, val_xm, train_ym, val_ym = train_test_split(mx, my, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scaled data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler = StandardScaler()  \n",
    "# Don't cheat - fit only on training data\n",
    "scaler.fit(train_x) \n",
    "scaler.fit(train_xm)\n",
    "strain_x = scaler.transform(train_x)\n",
    "strain_xm = scaler.transform(train_xm)\n",
    "# apply same transformation to test data\n",
    "sval_x = scaler.transform(val_x)  \n",
    "sval_xm = scaler.transform(val_xm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(criterion='entropy')\n",
    "title = \"Decision Tree (no pruning)\"\n",
    "plot_learning_curve(tree,title,train_x, train_y, ylim=(0.1,1.01),cv=5,n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "crossVal = cross_val_score(tree, train_x, train_y, cv=5)\n",
    "print(\"Unpruned:\",np.mean(crossVal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,15):\n",
    "    print(i)\n",
    "    tree = DecisionTreeClassifier(criterion='entropy',max_depth=i)\n",
    "    title = \"Decision Tree of Max Depth: \" + str(i)\n",
    "    plot_learning_curve(tree,title, train_x, train_y, ylim=(0.1, 1.01), cv=5, n_jobs=4)\n",
    "    crossVal = cross_val_score(tree, train_x, train_y, cv=5)\n",
    "    print(\"Pruned:\",i,np.mean(crossVal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(criterion='entropy',max_depth=7)\n",
    "pred_y = tree.fit(train_x, train_y).predict(val_x)\n",
    "cnf_matrix = confusion_matrix(val_y, pred_y)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, \n",
    "                      classes=['Angry','Fear','Happy','Sad','Surprise','Neutral'],\n",
    "                      normalize=True, title='Decision Tree Confusion Matrix')\n",
    "print(\"F1 Score\", f1_score(pred_y, val_y,average='weighted'))\n",
    "print(\"Score\", tree.score(val_x, val_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sizes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Decision Tree (n=245)\"\n",
    "plot_learning_curve(tree,title, train_xm, train_ym, ylim=(0.0, 1.01), cv=5, n_jobs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Default Neural Network\"\n",
    "nn = MLPClassifier(solver='lbfgs',random_state=1,early_stopping=True)\n",
    "plot_learning_curve(nn,title, strain_x, train_y, ylim=(0.0, 1.01), cv=5, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossVal = cross_val_score(nn, strain_x, train_y, cv=5)\n",
    "print(\"Untuned:\",np.mean(crossVal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'solver':['adam','sgd','lbfgs'],'alpha': 10**-np.arange(1,7,dtype=float),\n",
    "          'learning_rate':['constant','adaptive']}\n",
    "search = GridSearchCV(estimator=nn, param_grid=params,cv=3)\n",
    "search.fit(strain_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Neural Network After Tuning Hyperparameters\"\n",
    "tunedNN = MLPClassifier(solver='lbfgs',random_state=1,alpha=0.1)\n",
    "param1 = {'hidden_layer_sizes': range(200,4201,1000)}\n",
    "param2 = {'hidden_layer_sizes': [(x,100) for x in range(200,4201,1000)]}\n",
    "rSearch1 = GridSearchCV(estimator=tunedNN, \n",
    "                            param_grid=[param1,param2])\n",
    "rSearch1.fit(strain_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunedNN = search.best_estimator_\n",
    "print(tunedNN)\n",
    "plot_learning_curve(tunedNN, title, strain_x, train_y, ylim=(0.0, 1.01), cv=5, n_jobs=4)\n",
    "crossVal = cross_val_score(tunedNN, strain_x, train_y, cv=5)\n",
    "print(\"Tuned:\",np.mean(crossVal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = tunedNN.fit(strain_x, train_y).predict(val_X)\n",
    "cnf_matrix = confusion_matrix(sval_y, pred_y)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, \n",
    "                      classes=['Angry','Fear','Happy','Sad','Surprise','Neutral'],\n",
    "                      normalize=True, title='Neural Network Confusion Matrix')\n",
    "print(\"Score\", tunedNN.score(sval_X, val_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sizes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Neural Network (n=245)\"\n",
    "plot_learning_curve(tree,title, strain_xm, train_ym, ylim=(0.0, 1.01), cv=5, n_jobs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "bdt = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(criterion='entropy',max_depth=1))\n",
    "bdt.fit(train_x, train_y)\n",
    "title = \"Default AdaBoost\"\n",
    "plot_learning_curve(bdt,title, train_x, train_y, ylim=(0.1, 1.01), cv=5, n_jobs=4)\n",
    "crossVal = cross_val_score(bdt, train_x, train_y, cv=5)\n",
    "print(\"Untuned\",np.mean(crossVal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'learning_rate': np.logspace(-3,2,3),'n_estimators':range(10,1000,100)}\n",
    "search = GridSearchCv(estimator=bdt, param_grid=params,scoring='f1')\n",
    "search.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"AdaBoost After Tuning Hyperparameters\"\n",
    "bdt = search.best_estimator_\n",
    "plot_learning_curve(bdt, title, train_X, train_y, ylim=(0.0, 1.01), cv=5, n_jobs=4)\n",
    "crossVal = cross_val_score(bdt, train_X, train_y, cv=5)\n",
    "print(\"Tuned:\",np.mean(crossVal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdt = search.best_estimator_\n",
    "pred_y = bdt.fit(train_x, train_y).predict(val_X)\n",
    "cnf_matrix = confusion_matrix(sval_y, pred_y)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, \n",
    "                      classes=['Angry','Fear','Happy','Sad','Surprise','Neutral'],\n",
    "                      normalize=True, title='AdaBoost Confusion Matrix')\n",
    "print(\"Score\", bdt.score(sval_X, val_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sizes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"AdaBoost (n=245)\"\n",
    "plot_learning_curve(bdt,title, strain_xm, train_ym, ylim=(0.0, 1.01), cv=5, n_jobs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "svmClf = svm.SVC()\n",
    "svmClf.fit(strain_x, train_y)\n",
    "title = \"Default SVM\"\n",
    "plot_learning_curve(svmClf,title, strain_x, train_y, ylim=(0.5, 1.01), cv=5, n_jobs=4)\n",
    "crossVal = cross_val_score(svmClf, strain_x, train_y, cv=5)\n",
    "print(\"Untuned\",np.mean(crossVal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'gamma': np.logspace(-5,-3,3),'C':np.logspace(0,2,3),'kernel':['linear','rbf']}\n",
    "search = GridSearchCV(estimatro=svmClf,param_grid=params)\n",
    "search.fit(strain_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"SVM After Tuning Hyperparameters\"\n",
    "svmClf = search.best_estimator_\n",
    "plot_learning_curve(svmClf, title, strain_x, train_y, ylim=(0.0, 1.01), cv=5, n_jobs=4)\n",
    "crossVal = cross_val_score(bdt, strain_x, train_y, cv=5)\n",
    "print(\"Tuned:\",np.mean(crossVal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmClf = search.best_estimator_\n",
    "pred_y = svmClf.fit(strain_x, train_y).predict(sval_x)\n",
    "cnf_matrix = confusion_matrix(val_y, pred_y)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, \n",
    "                      classes=['Angry','Disgust','Fear','Happy','Sad','Surprise','Neutral'],\n",
    "                      normalize=True, title='SVM Confusion Matrix')\n",
    "print(\"Score\", svmClf.score(sval_x, val_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sizes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"SVM (n=245)\"\n",
    "plot_learning_curve(svmClf,title, strain_xm, train_ym, ylim=(0.0, 1.01), cv=5, n_jobs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "knn = neighbors.KNeighborsClassifier()\n",
    "knn.fit(strain_x, train_y)\n",
    "title = \"Default k-NN\"\n",
    "plot_learning_curve(knn,title, strain_x, train_y, ylim=(0.0, 1.01), cv=5, n_jobs=4)\n",
    "crossVal = cross_val_score(knn, strain_x, train_y, cv=5)\n",
    "print(\"Untuned\",np.mean(crossVal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {'n_neighbors': range(1,111,10), 'weights':['uniform','distance'], 'p': range(1,3)}\n",
    "gs = GridSearchCV(estimator=knn, param_grid=params,cv=3,scoring='f1_weighted')\n",
    "gs.fit(strain_x, train_y)\n",
    "print(gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"k-NN After Tuning\"\n",
    "knn = gs.best_estimator_\n",
    "plot_learning_curve(knn, title, strain_x, train_y, ylim=(0.0, 1.01), cv=5, n_jobs=4)\n",
    "crossVal = cross_val_score(knn, strain_x, train_y, cv=5)\n",
    "print(\"Tuned:\",np.mean(crossVal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = search.best_estimator_\n",
    "pred_y = knn.fit(strain_x, train_y).predict(sval_x)\n",
    "cnf_matrix = confusion_matrix(sval_y, pred_y)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, \n",
    "                      classes=['Angry','Fear','Happy','Sad','Surprise','Neutral'],\n",
    "                      normalize=True, title='k-NN Confusion Matrix')\n",
    "print(\"Score\", knn.score(sval_X, val_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sizes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"kNN (n=245)\"\n",
    "plot_learning_curve(knn,title, strain_xm, train_ym, ylim=(0.0, 1.01), cv=5, n_jobs=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
